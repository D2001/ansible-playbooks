---
- name: Backup Docker service and upload to OneDrive
  hosts: localhost

  vars:
    base_dir: "/home/karsten"
    service_name: "temp_service"
    service_dir: "{{ base_dir }}/{{ service_name }}"
    backup_dir: "{{ base_dir }}/backups/{{ service_name }}_backups"
    nas_backup_dir: "/mnt/backups/{{ service_name }}"
    rclone_remote: "onedrive:{{ service_name }}_backups"
    backup_pattern: "{{ service_name }}_backup_*.tar.gz"
    compose_file: "{{ service_dir }}/docker-compose.yml"
    timestamp: "{{ ansible_date_time.iso8601_basic_short }}"
    backup_file: "{{ service_name }}_backup_{{ timestamp }}.tar.gz"
    max_local_backups: 1
    max_onedrive_backups: 7
    max_nas_backups: 30
    # Compression settings for better performance
    tar_compression_level: 1  # Fast compression
    parallel_jobs: "{{ ansible_processor_vcpus | default(2) }}"

  tasks:
    # Pre-flight checks
    - name: Verify service directory exists
      stat:
        path: "{{ service_dir }}"
      register: service_dir_stat
      failed_when: not service_dir_stat.stat.exists

    - name: Verify docker-compose file exists
      stat:
        path: "{{ compose_file }}"
      register: compose_file_stat
      failed_when: not compose_file_stat.stat.exists

    - name: Ensure backup directories exist (parallel creation)
      file:
        path: "{{ item }}"
        state: directory
        owner: karsten
        group: karsten
        mode: '0755'
      loop:
        - "{{ backup_dir }}"
        - "{{ nas_backup_dir }}"

    # Use block with rescue to ensure containers are always restarted
    - block:
        - name: Stop {{ service_name }} containers
          shell: docker compose down
          args:
            chdir: "{{ service_dir }}"
          register: stop_result

        - name: Check for Docker volumes related to {{ service_name }}
          shell: docker volume ls --format "{% raw %}{{.Name}}{% endraw %}" | grep "{{ service_name }}" || true
          register: docker_volumes_result
          failed_when: false
          changed_when: false

        - name: Set service volumes fact
          set_fact:
            service_volumes: "{{ docker_volumes_result.stdout_lines | default([]) }}"

        - name: Create archive of the {{ service_name }} directory (no volumes case)
          community.general.archive:
            path: "{{ service_dir }}"
            dest: "{{ backup_dir }}/{{ backup_file }}"
            format: gz
            owner: karsten
            group: karsten
            mode: '0644'
          when: service_volumes | length == 0

        - name: Create temporary directory for volume backups
          tempfile:
            state: directory
            suffix: _{{ service_name }}_backup
          register: temp_backup_dir
          when: service_volumes | length > 0

        - name: Backup Docker volumes in parallel
          shell: |
            docker run --rm \
              -v {{ item }}:/volume:ro \
              -v {{ temp_backup_dir.path }}:/backup \
              --name backup_{{ item | regex_replace('[^a-zA-Z0-9]', '_') }} \
              alpine:latest \
              tar czf /backup/{{ item }}.tar.gz -C /volume .
          loop: "{{ service_volumes }}"
          when: service_volumes | length > 0
          async: 300
          poll: 0
          register: volume_backup_jobs

        - name: Wait for volume backups to complete
          async_status:
            jid: "{{ item.ansible_job_id }}"
          loop: "{{ volume_backup_jobs.results }}"
          register: volume_backup_results
          until: volume_backup_results.finished
          retries: 60
          delay: 5
          when: service_volumes | length > 0

        - name: Create combined archive with service directory and volumes
          shell: |
            cd "{{ service_dir | dirname }}"
            # Use pigz for parallel compression if available, fallback to gzip
            COMPRESSOR="gzip"
            if command -v pigz >/dev/null 2>&1; then
              COMPRESSOR="pigz -{{ tar_compression_level }} -p {{ parallel_jobs }}"
            fi
            
            # Create uncompressed tar first
            tar cf "{{ backup_dir }}/{{ backup_file }}.tmp" "{{ service_name }}"
            cd {{ temp_backup_dir.path }}
            # Append volume backups to uncompressed tar
            tar rf "{{ backup_dir }}/{{ backup_file }}.tmp" *.tar.gz 2>/dev/null || true
            # Compress the final archive
            $COMPRESSOR "{{ backup_dir }}/{{ backup_file }}.tmp"
            mv "{{ backup_dir }}/{{ backup_file }}.tmp.gz" "{{ backup_dir }}/{{ backup_file }}"
          args:
            executable: /bin/bash
          when: service_volumes | length > 0

        - name: Clean up temporary backup directory
          file:
            path: "{{ temp_backup_dir.path }}"
            state: absent
          when: service_volumes | length > 0

        - name: Verify backup file was created and has reasonable size
          stat:
            path: "{{ backup_dir }}/{{ backup_file }}"
          register: backup_stat
          failed_when: not backup_stat.stat.exists or backup_stat.stat.size < 1024  # At least 1KB

        - name: Upload operations in parallel
          include_tasks: upload_backup.yml

      rescue:
        - name: Log backup failure
          debug:
            msg: "Backup failed: {{ ansible_failed_result.msg | default('Unknown error') }}"
          
        - name: Fail the playbook
          fail:
            msg: "Backup process failed, but containers will be restarted"

      always:
        - name: Start {{ service_name }} containers
          shell: docker compose up -d
          args:
            chdir: "{{ service_dir }}"
          register: start_result
